<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>paper on Pan'Log</title><link>https://payne4handsome.github.io/categories/paper/</link><description>Recent content in paper on Pan'Log</description><image><title>Pan'Log</title><url>https://payne4handsome.github.io/papermod-cover.png</url><link>https://payne4handsome.github.io/papermod-cover.png</link></image><generator>Hugo -- gohugo.io</generator><lastBuildDate>Mon, 22 May 2023 14:37:57 +0800</lastBuildDate><atom:link href="https://payne4handsome.github.io/categories/paper/index.xml" rel="self" type="application/rss+xml"/><item><title>BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation</title><link>https://payne4handsome.github.io/posts/papers/2023-05-22-blip/</link><pubDate>Mon, 22 May 2023 14:37:57 +0800</pubDate><guid>https://payne4handsome.github.io/posts/papers/2023-05-22-blip/</guid><description>Title: BLIP: 引导语言-图像预训练，用于统一的视觉-语言理解和生成 作者: Junnan Li Dongxu Li Caiming Xiong Steven Hoi；Salesforce Research 发表日期：2022.2 github: https://github.com/salesforce/BLIP 该论文试图解决什么问题？ 目前已经存在的VLP（Vision-Language Pre-training）模型仅仅在理解类任务（understanding-based tasks）或者生成类任务（generation-based tasks）一方面表现优秀。主要解决问题有二。
提出BLIP，一个新的可以灵活迁移到理解类任务和生成类任务的VLP架构。 (CapFilt): 网络爬取的数据有噪声，该方法可以提升数据的质量。 Key Contributions 提出MED（ultimodal mixture of Encoder-Decoder）架构: 可以有效的多任务预训练和迁移学习。 通过三个视觉-语言目标函数实现：imagetext contrastive learning, image-text matching, and imageconditioned language modeling. 提出CapFilt（Captioning and Filtering）方法: 从有噪声的数据训练。captioner模块：输入网络爬取的图片，输出合成的文本描述（caption 任务）， filter模块L：从合成的图像文本对和合成的图像文本对中删除质量差的数据（noisy captions）. Method 模型结构 note: 颜色相同的模块共享参数
主要分为三个模块
Unimodal encoder: 单模态的encoder， 包括图像encoder， 文本encoder Image-grounded text encoder: 通过cross-attention进入视觉信息 Image-grounded text decoder: 用于生成任务 预训练目标函数 Image-Text Contrastive Loss (ITC) 作用：视觉特征空间与文本特征空间对齐（CLIP思想） 实现方式：同一个batch中配对的图像和文本是正样本，不配置的图像和文本是负样本（自已构建正负样本对）。计算cos距离后正样本打高分，负样本打低分。 Image-Text Matching Loss (ITM) 作用：捕获更细粒度的图像文本对齐特征 实现方式：网络最后接一个全连接层做一个二分类任务。note：与ITC不同 Language Modeling Loss (LM) 作用：给定图片生成描述 实现方式：交叉熵 CapFilt 先用网络爬取的数据和人类标注的数据集预训练模型。然后**各自的（指参数不共享）**的finetune captioner模块和filter模块。</description></item><item><title>LoRA: Low-RanK Adaption Of Large Language Models</title><link>https://payne4handsome.github.io/posts/papers/2023-05-09-lora-low-rank-adaptation-of-large-lan-guage-models/</link><pubDate>Tue, 09 May 2023 21:28:47 +0800</pubDate><guid>https://payne4handsome.github.io/posts/papers/2023-05-09-lora-low-rank-adaptation-of-large-lan-guage-models/</guid><description>Title: LoRA: 大语言模型的低秩适配 作者: {edwardhu, yeshe, phwallis, zeyuana, yuanzhil, swang, luw, wzchen}@microsoft.com yuanzhil@andrew.cmu.edu 发表日期：2021.10 该论文试图解决什么问题？ 提出一个大模型的低秩适配方法去解决全量微调大模型时候需要全量更新模型参数、显存占用很大的问题。
Key Contributions 对于不同的下游任务，大模型的参数是共享的，变化的只不过是LoRA方法新引入的参数（即B、A参数矩阵）。所以如果有比较多的下游任务，大模型参数只需要保存一份，切换任务的时候也只需要切换一下B、A矩阵即可。大大减少了模型存储的空间和任务切换时候的负载 LoRA方法可以使训练更有效（耗时减少）、减少3倍的显存使用。因为不用保存原始大模型参数的梯度。eg，GPT-3训练需要1.2T显存，使用LoRA方法显存只需要350G左右 不增加推理耗时（上面已经提到） 可以和其他的适配方法结合，比如prefix-tuning Abstract &amp;amp; Introduction &amp;amp; Method NLP模型使用的一个通用范式是先选择一个大的在通用数据集上训练的预训练模型，然后再在一个特定任务上做fine-tune。 但是如果做全量的fine-tune，就要更新模型所有的参数。比如GPT-3有1750亿的参数。fine-tune需要更新1750亿的参数，这个操作是昂贵的。本文提出一个名为LoRA(Low-Rank Adaption)的方法：freeze 预训练模型的参数，在原有的模型结构中插入低秩分解矩阵（rank decomposition matrices）. 该方法可以极大的减少模型的训练参数。
方法示意图如下 右边橙色的为新引入的可训练的低秩矩阵，其它的为原始模型的参数。数学表达可能更清楚一点。原始模型的前向过程表达为
$$h = W_0x$$, 修改后的前向过程如下：
$$h = W_0x+\Delta Wx=W_ox+BAx$$
LoRA核心的方法就是改公式。在模型保存的时候可以将$W_0+\Delta W$保存（即加起来），所以改方法不会增加模型的推理耗时
Experiments 与不同适配方法在GLUE上的对比 在GPT-3上的适配效果对比 不同方法加大可训练参数量效果对比 Transformer结构为例，LoRA加到哪里更有效？ 参数总量不变（秩r改变），加的地方不一样。实验表明加到$W_q$,$W_v$上效果更好
r是不是越大越好？ 实验表明，r并不是越大效果越好，对于一些任务，r=4就足够了（取1效果也不错）。对于这个结论论文有一些说明，大致的意思就是r=4的时候，参数量已经够要学习的信息了，再打也是无非是引入冗余的信息罢了。这里解析的可以有失偏颇，感兴趣的参见原文为好。
CONCLUSION AND FUTURE WORK 关于未来的工作方向。
LoRA可以和其他迁移方法结合 fine-tuning或者LoRA背后的机制是不清楚的，如何将在预训练的时候学习到的特征迁移到下游任务？作者认为LoRA比full fine-tuning做更好。 作者将LoRA添加到参数矩阵，是通过穷尽、实验的方式，有没有更好的指导原则？ 既然LoRA可以通过添加一个低秩的矩阵就可以取到好的效果，那么原始的参数矩阵是不是也可以降低一下秩？。 第4点确实是一个比较好、且重要的研究方向。</description></item></channel></rss>