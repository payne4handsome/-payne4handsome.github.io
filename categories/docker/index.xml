<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>docker on Pan'Log</title><link>https://payne4handsome.github.io/categories/docker/</link><description>Recent content in docker on Pan'Log</description><image><title>Pan'Log</title><url>https://payne4handsome.github.io/papermod-cover.png</url><link>https://payne4handsome.github.io/papermod-cover.png</link></image><generator>Hugo -- gohugo.io</generator><atom:link href="https://payne4handsome.github.io/categories/docker/index.xml" rel="self" type="application/rss+xml"/><item><title>docker命令</title><link>https://payne4handsome.github.io/posts/basic/docker%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://payne4handsome.github.io/posts/basic/docker%E5%91%BD%E4%BB%A4/</guid><description>基础命令 查看有那些镜像 xxxxx:5000/v2/_catalog 查看具体项目的tag列表 xxxx:5000/v2/project/repo/tags/list 启动一个镜像 docker run -it --rm -v $PWD:/tmp -w /tmp self_image_name self_command 其中
-v: 将宿主的目录挂载到容器内部 -w: 指定工作目录 启动一个镜像(web应用，需要端口映射) docker run -it --rm -v $PWD:/tmp -w /tmp -p 5000:5000 self_image_name self_command 查看容器内部的标准输出 docker logs -f bf08b7f2cd89 查看容器内部运行的进程 docker top wizardly_chandrasekhar 查看容器的配置和状态信息 docker inspect wizardly_chandrasekhar 更新镜像 docker commit -m=&amp;#34;has update&amp;#34; -a=&amp;#34;runoob&amp;#34; e218edb10161 runoob/ubuntu:v2 打tag（push到仓库） docker tag 860c279d2fec runoob/centos:dev GPU 环境安装 NVIDIA Docker 安装 如需在 Linux 上启用 GPU 支持，请安装 NVIDIA Docker 支持 验证 nvidia-docker 安装效果</description></item><item><title>nvidia smi docker usage</title><link>https://payne4handsome.github.io/posts/basic/nvidia-smi-docker-usage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://payne4handsome.github.io/posts/basic/nvidia-smi-docker-usage/</guid><description>正文 docker 和 nvidia-docker命令的区别
如果容器中需要用到cuda，但是使用docker 启动是找不到cuda的，nvidia-smi命令也无法使用。必须使用nvidia-docker启动。经试验，如下命令也是ok的，docker指定参数 &amp;ndash;gpus
docker run --rm --gpus all nvidia/cuda nvidia-smi 指定使用那一块GPU
使用全部的gpu docker run --rm --gpus all nvidia/cuda nvidia-smi 使用环境变量NVIDIA_VISIBLE_DEVICES来指定使用那一个GPU（必须指定runtime，&amp;ndash;runtime=nvidia） docker run --rm --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=all nvidia/cuda nvidia-smi 容器内可以使用两块gpu docker run --rm --gpus 2 nvidia/cuda nvidia-smi 指定gpu编号 docker run --gpus &amp;#39;&amp;#34;device=1,2&amp;#34;&amp;#39; nvidia/cuda nvidia-smi --query-gpu=uuid --format-csv [参考文档] https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html nvidia-docker2 安装</description></item></channel></rss>