<!doctype html><html lang=zh dir=auto><head><meta name=generator content="Hugo 0.112.0-DEV"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Pan'Log</title><meta name=description content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod"><meta name=author content="Pan"><link rel=canonical href=https://payne4handsome.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.541955f499cd4d76b0863a0426411d26c7eb9a4b1c5a15e91740b02838d41e68.css integrity="sha256-VBlV9JnNTXawhjoEJkEdJsfrmkscWhXpF0CwKDjUHmg=" rel="preload stylesheet" as=style><link rel=icon href=https://payne4handsome.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://payne4handsome.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://payne4handsome.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://payne4handsome.github.io/apple-touch-icon.png><link rel=mask-icon href=https://payne4handsome.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/json href=https://payne4handsome.github.io/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Pan'Log"><meta property="og:description" content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod"><meta property="og:type" content="website"><meta property="og:url" content="https://payne4handsome.github.io/"><meta property="og:image" content="https://payne4handsome.github.io/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://payne4handsome.github.io/papermod-cover.png"><meta name=twitter:title content="Pan'Log"><meta name=twitter:description content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Pan'Log","url":"https://payne4handsome.github.io","description":"Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod","thumbnailUrl":"https://payne4handsome.github.io/favicon.ico","sameAs":[]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class="header intro-header" style=background-image:url(cover001.jpg)><nav class=nav><div class=logo><a href=https://payne4handsome.github.io accesskey=h title="Pan'Log (Alt + H)">Pan'Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://payne4handsome.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://payne4handsome.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://payne4handsome.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://payne4handsome.github.io/archives title=Archive><span>Archive</span></a></li></ul></nav><article class="first-entry1 home-info"><header class=entry-header><h1>Pan&rsquo;Blog</h1></header><div class=entry-content><p>Welcome to pan&rsquo;s blog.</p><ul><li>Hi, this is <strong>Zhang Pan</strong>. I’m documenting my learning notes in this blog.</li><li>Email: <a href=mailto:payne4handsome@163.com>payne4handsome@163.com</a>.</li></ul></div><footer class=entry-footer><div class=social-icons></div></footer></article></header><main class=main><article class=post-entry><header class=entry-header><h2>Flamingo</h2></header><div class=entry-content><p>Title: Flamingo: a Visual Language Model for Few-Shot Learning 作者: Jean-Baptiste Alayrac, Jeff Donahue 发表日期: 2022.11 一、Introduction 1.1 该论文试图解决什么问题？ 多模领域的few-shot问题
1.2 Key Contributions 提出Flamingo模型，通过几个示例就可执行各种多模任务。由于架构的创新，Flamingo可以处理随意的图片（可以多张图片）和文本 通过few-shot学习，定量评估Flamingo是如何迁移到其他各种任务的 通过few-shot学习，Flamingo在16任务中的6个任务(6个人任务是finetune过的)取到SOTA。Flamingo可以在其他数据集上通过fine-tune取到SOTA。 Method Flamingo架构总览如下图 从图中可以看到Flamingo架构有两个关键点组件，Perceiver Resampler和Gated XATTN-DENSE
Perceiver Resampler: 任意数量的图片或者视频经过视觉模型编码后，再通过Pereiver Resampler输出固定数量的visual tokens。注：该模块决定了Flamingo可以处理多张图片的能力（即具有few-shot的能力） Gated XATTN-DENSE: 主要是指cross attention的基础加入门机制(tanh(a), a初始化为0)，可以提升性能和训练的稳定性 Visual processing and the Perceiver Resampler Perceiver Resampler示意图如下，学习DETR的query机制，有几个query，输出就是几个visual token（论文中为5） Conditioning frozen language models on visual representations 在Transformer中的cross attention的基础加入门机制 Multi-visual input support: per-image/video attention masking 网络上爬取的文档是图片和文本交错的信息。该模块是用来控制当前文本token可以注意到的图片（离当前文本token最近的上一个图片）
Training on a mixture of vision and language datasets Flamingo训练采用了三个数据集：...</p></div><footer class=entry-footer><span title='2023-09-24 17:40:40 +0800 CST'>九月 24, 2023</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;pan</footer><a class=entry-link aria-label="post link to Flamingo" href=https://payne4handsome.github.io/posts/papers/2023-09-24-flamingo/></a></article><article class=post-entry><header class=entry-header><h2>MME</h2></header><div class=entry-content><p>Title: MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models 作者: Chaoyou Fu, Peixian Chen, Yunhang Shen, Yulei Qin, Mengdan Zhang, Xu Lin1Zhenyu Qiu, Wei Lin, Jinrui Yang, Xiawu Zheng, Ke Li, Xing Sun, Rongrong Ji; Tencent Youtu Lab , Xiamen University 发表日期: 2023.7 项目主页：MME Note: 项目主页加入了新的多模模型，得分已经远远超过论文的那个几个模型 一、Introduction 缩写
LLM: Large Language Model MLLM: Multimodal Large Language Model LLM 三个代表性的能力: In-Context Learning(ICL), instruction following, Chain-of-Thought (CoT)
1.1 该论文试图解决什么问题？ 多模模型缺乏一个全面的评估benchmark，该论文首次提出多模大模型的评估benchmark MME。在14个子任务上度量多模大模型的感知和认知能力。...</p></div><footer class=entry-footer><span title='2023-09-08 11:29:11 +0800 CST'>九月 8, 2023</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;pan</footer><a class=entry-link aria-label="post link to MME" href=https://payne4handsome.github.io/posts/papers/2023-09-08-mme/></a></article><article class=post-entry><header class=entry-header><h2>Efficient Training</h2></header><div class=entry-content><p>对于模型的训练，训练的速度和显存的占用是必须要考虑的两个因素，特别是现在模型越来越大。1.4B的模型，在32GB的GPU上训练就会OOM。更别提现在动不动就几百B甚至上千B的模型。所以分析那些因素对模型的训练速度和显存的占用是十分必要的。
显存占用分析（训练阶段） 在训练阶段，显存被如下组件占用
model weights optimizer states gradients forward activations saved for gradient computation temporary buffers functionality-specific memory 在ZeRO中model weights、optimizer states、gradients被称为模型状态（model states）, 剩下的被称为剩余状态（residual states）
具体的计算如下（参数量假设为1）
model weights 4 bytes ： fp32 training 6 bytes ： mixed precision training（即需要保存一个float32参数，又需要保存一个float16参数） Optimizer States 8 bytes：对于大模型优化器一般为AdamW（包含一阶梯度和二阶梯度，所以对于一个参数，优化器占用8个比特） 2 bytes：8-bit AdamW optimizer 4 bytes：SGD with momentum Gradients 4 bytes： fp32 or mixed precision training （注：对于混合精度训练，一个参数的梯度，ZeRO论文任务是2 bytes(float16), Hugging face中认为梯度一般是4 bytes(float32)。）。所以这里不太确定，获取两种计算方式都是正确的（由框架实现决定） 所以，如果使用混合精度训练，一个参数，需要消耗18个bytes（6+8+4）（ZeRO认为16个bytes）
减少显存使用和提升训练速度的tricks Method Speed Memory 备注 Gradient accumulation No Yes Gradient checkpointing No Yes Mixed precision training Yes (No) 不太严谨 Batch size Yes Yes Optimizer choice Yes Yes DataLoader Yes No DeepSpeed Zero No Yes 必要的解释...</p></div><footer class=entry-footer><span title='2023-08-28 14:02:00 +0800 CST'>八月 28, 2023</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;pan</footer><a class=entry-link aria-label="post link to Efficient Training" href=https://payne4handsome.github.io/posts/machine-learning/efficient-training-on-a-single-gpu/></a></article><article class=post-entry><header class=entry-header><h2>Openai GPT Prompt 官方教程</h2></header><div class=entry-content><p>openai官方教程(六大策略) Six strategies for getting better results
一、Write clear instructions Include details in your query to get more relevant answers 在你的问题中包含细节，以获得更相关的答案
bad good Who’s president? Who was the president of Mexico in 2021, and how frequently are elections held? Write code to calculate the Fibonacci sequence. Write a TypeScript function to efficiently calculate the Fibonacci sequence. Comment the code liberally to explain what each piece does and why it’s written that way....</p></div><footer class=entry-footer><span title='2023-07-31 14:02:00 +0800 CST'>七月 31, 2023</span>&nbsp;·&nbsp;14 分钟&nbsp;·&nbsp;pan</footer><a class=entry-link aria-label="post link to Openai GPT Prompt 官方教程" href=https://payne4handsome.github.io/posts/machine-learning/openai-gpt-prompt-%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/></a></article><article class=post-entry><header class=entry-header><h2>IMAGEBIND: One Embedding Space To Bind Them All</h2></header><div class=entry-content><p>一、Introduction 1.1 该论文试图解决什么问题？ 该论文主要解决的多模态对齐的问题，该论文将图片（视频）、文本、音频、深度图、热力图（thermal）、IMU六种模态的特征对齐在一个空间。 所以IMAGEBIND可以做跨模态召回（cross-modal retrieval）、简单相加融合模态信息（composing modalities with arithmetic）、跨模态检测和生成（cross-modal detection and generation）等任务。另外IMAGEBIND的few-shot能力也不错
补充说明 目前主流的方法还是将图片和文本（或者声音）对齐，比如CLIP（Audio-CLIP）。但是没有像IMAGEBIND方法这样讲6种模态的特征对齐，本质原因是没有6种模态对齐的训练数据（指一条样本对包含的6种模态数据完成对应）。但是每一种模态和图片成对的数量是够的，就是（图片-文本）、（图片-音频）、（图片-深度图）、（图片-热力图）、（图片-IMU）这种成对的数据是够的。IMAGEBIND就是把所有模态的数据都和图片这个模态的数据进行对齐。那么比如（文本-音频）、（文本-深度图）等跨模态的数据就也对齐的。这种在数学上叫做传递性，因为所有模态的相似度量是用的cosine距离，这个度量方式就是可传递的，所以IMAGEBIND能把这么多模态对齐是显然的。 emergent zero-shot：由于IMAGEBIND是将其他模态和图片模态配对然后训练，其它的模态对是没有进行训练的，比如（文本-音频）、（文本-深度图）。所以（文本-音频）的召回或者分类能力，IMAGEBIND叫做涌现的zero-shot能力。 至于网络结构损失函数等，并没有新的东西。甚至图像-文本的模态对齐就是用的CLIP（文中用的OPEN-CLIP），直接frozen掉没有训练 Method ImageBind的网络结构没有什么新的架构，无非就是不同规模的VIT结构。损失与CLIP的对比损失不同，用的是InfoNCE loss。公式如下：
其中$q_i$, $k_i$分别表示图片、其它模态数据经过encoder后的embedding。$\tau$表示温度，用于控制softmax后的平滑程度。
Experiments ImageBind的应用 跨模态召回 embeding相加就等价于语义的相加 声音生产图片 ImageBind使用的数据样例 都是自然与图片配对的数据 ImageBind使用的评测数据集 可以看到都是分类、召回类的任务 Emergent zero-shot分类能力 音频的分类任务重ImageBind与AudioCLIP对比，但是AudioCLIP是直接在（text, audio）成对的数据上训练的，且AudioCLIP用到了AS类别信息，所以ImageBind提到AudioCLIP的指标不能算zero-shot，所以AudioCLIP的指标对ImageBind的高一点 文本召回视频 A: Audio, V:Video。 可以看到用音频和图片的联合embedding取得了最好的效果。 Few-shot能力 使用不同规模的Image Encoder 关于温度（损失函数中用于控制平衡的参数，见损失公式）$\tau$的影响</p></div><footer class=entry-footer><span title='2023-06-26 23:15:33 +0800 CST'>六月 26, 2023</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;pan</footer><a class=entry-link aria-label="post link to IMAGEBIND: One Embedding Space To Bind Them All" href=https://payne4handsome.github.io/posts/papers/2023-06-26-imagebind/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://payne4handsome.github.io/>«&nbsp;上一页&nbsp;</a>
<a class=next href=https://payne4handsome.github.io/page/3/>下一页&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://payne4handsome.github.io>Pan'Log</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>