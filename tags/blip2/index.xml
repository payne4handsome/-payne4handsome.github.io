<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>BLIP2 on Pan'Log</title><link>https://payne4handsome.github.io/tags/blip2/</link><description>Recent content in BLIP2 on Pan'Log</description><image><title>Pan'Log</title><url>https://payne4handsome.github.io/papermod-cover.png</url><link>https://payne4handsome.github.io/papermod-cover.png</link></image><generator>Hugo -- gohugo.io</generator><lastBuildDate>Mon, 15 May 2023 16:00:20 +0800</lastBuildDate><atom:link href="https://payne4handsome.github.io/tags/blip2/index.xml" rel="self" type="application/rss+xml"/><item><title>BLIP-2:Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</title><link>https://payne4handsome.github.io/posts/papers/2023-05-15-blip2/</link><pubDate>Mon, 15 May 2023 16:00:20 +0800</pubDate><guid>https://payne4handsome.github.io/posts/papers/2023-05-15-blip2/</guid><description>Title: BLIP-2: 用冻住的图像编码模型和大语言模型引导文本-图像预训练 作者: Junnan Li Dongxu Li Silvio Savarese Steven Hoi；Salesforce Research 发表日期：2023.5 github: https://github.com/salesforce/LAVIS/tree/main/projects/blip2 该论文试图解决什么问题？ 预训练视觉-语言模型代价变的非常高昂，由于端到端的训练。这篇论文提出了一个通用的、有效的预训练策略：BLIP-2，其从现成的冻住的图像编码模型和冻住的大语言模型引导视觉-语言（vision-language）的预训练。该方法解决的跨模态对齐问题。
Method 两阶段策略，预训练一个轻量级Q-Former模块去连接两种模态的gap。第一阶段：从一个frozen image encoder中引导visionlanguage表示学习（representation learning）。第二阶段：从一个frozen LLM中引导vision-to-language的生成学习（generative learning）</description></item></channel></rss>